---
title: "Online Dating"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


TEAM NAME: coccinelle 


TEAM MEMBERS: Carlotta Zatti (carlotta zatti), Federica Zattini (FZattini)






L'obiettivo dell'analisi è prevedere se la professione di una persona è STEM (science, technology, engineering, and math) o no. Il metodo usato per la valutazione della performance dei modelli Ã¨ l'AUC (Area under the ROC curve). 
Il training set include 6000 utenti, di cui 1095 sono nell'ambito STEM. Si riscontra un problema limitato di class imbalance: il 18.25% di profili sono STEM. Il test set è composto da 4000 osservazioni.

I dati originali contengono variabili di diversa natura:

* 1 numerica (`essay_length`), 3 interi (`height`,`age`,`last_online`), 17 categoriali, 87 dummies
* Il numero delle categorie spazia da 51 (`where_town`) a 3 (`orientation`)
* I missing sono presenti nelle variabili categoriali come modalità: es. `drinks` ha livello `drinks_missing`
* In alcuni casi delle categorie presenti nel test set non sono incluse nel training set, per questo analizziamo il dataset come combinazione dei due.

A seguito delle analisi le variabili da 108 sono diventate 95, così suddivise:

* 1 numerica (`essay_length`), 2 interi (`height`,`age`), 22 categoriali, 70 dummies

Dato il grande numero di variabili categoriali, consideriamo gli alberi di classificazione perché: 

* sanno gestire predittori sia numerici che categoriali
* possono usare le variabili categoriali nella loro forma naturale (senza conversioni in dummy)
* sanno gestire i valori mancanti
* feature selection intrinseca nel processo così come le interazioni tra predittori

Il modello utilizzato per la previsione finale è il Random Forest per stabilizzare gli alberi.



*Summary of the modelling process:*



1. *Preprocessing* <br>

Nelle variabili `age`, `height` e `essay_length` sono presenti degli outliers. Per questo motivo si è deciso di sostituire dei valori in corrispondenza di 4 osservazioni:

* 1258: `height`pari a 26
* 3184: `age` 95 e `height` 25 
* 5201: `height` pari a 4
* 5676: `height` pari a 3

Per quanto riguarda le osservazioni 1258, 5201 e 5676, dove i valori anomali sono tutti in corrispondenza di `height`, si è deciso di condizionarsi alla variabile `age` e calcolare la mediana, misura più robusta data la distribuzione asimmetrica di `height`.
Per sistemare l'osservazione 3184 si è scelto di condizionarsi alla variabile `body_type` ed `education` al fine di correggere i valori `height` e `age`.

2. *Missing values* <br>

I missing sono presenti solo nelle variabili categoriali sottoforma di modalità e per questo motivo sono stati trattati come tali.

3. *Feature engineering* <br>

* Le modalità della variabile `education` sono diminuite da 33 a 17 per compattare le aree di interesse degli utenti
* Il predittore `income` è passato inizialmente da categoriale a numerico e successivamente è tornato categoriale con 3 modalità: `alto`, `basso` e `mancante`. La ripartizione è definita in modo da suddividere le categorie `alto` e `basso` in intervalli di ampiezza quasi simile (da 20000 fino a 50000 `basso`, da 50000 fino a 1000000 `alto`), mentre `mancante` individua tutti i missing.
* La variabile `last_online`  da intera è diventata categoriale con 2 modalità: `frequenti` e `meno_frequenti`. La suddivisione è generata sulla base della mediana, così da separare equamente gli utenti.
* Le categorie del predittore `smokes` sono diminuite da 6 a 3: `fumo`, `non fumo` e `missing`. 
* Le modalità della variabile `status` sono diminuite da 5 a 3: `single`, `occupato` e `missing`.
* Le dummies `cpp`, `cpp_fluently`, `cpp_okay` e `cpp_poorly` sono accorpate sotto un'unica variabile categoriale `cono_cpp` con 3 modalità `poca`,`buona`,`fluente` per indicare la conoscenza del programma cpp.
* Le dummies `lisp`, `lisp_fluently`, `lisp_okay` e `lisp_poorly` sono accorpate sotto un'unica variabile categoriale `cono_lisp` con 3 modalità: `poca`,`buona`,`fluente` per indicare la conoscenza del programma lisp.
* Per creare un'interazione tra i due programmi cpp e lisp si è creata una variabile `cpp_and_lisp` con 3 categorie: `entrambi`, `almeno uno` e `nessuno`. Questa ripartizione serve per stabilire se gli utenti conoscono entrambi i programmi, ne conoscono almeno uno dei due o nessuno. 
* Le dummies `asian`, `black`, `indian`, `ispanic_latin`, `middle-eastern`, `native_american`, `other`, `pacific_islander`e `white` sono accorpate sotto un'unica variabile categoriale `etnie` con 9 modalità. 

4. *Feature selection* <br>

Feature selection implementata automaticamente all'interno degli alberi.

5. *Final model* <br>

Il modello finale è un RandomForest ed è implementato dalla funzione train della libreria `caret` con `method = "rf"`, `metric = "ROC"` e `trControl = ctrl`. Ctrl è il risultato della funzione `trainControl` con `method = "cv"`, `number = 10`, `classProbs = TRUE`, `summaryFunction = twoClassSummary`. 
Dato che la risposta ha un problema di class imbalance, si è deciso di utilizzare un campionamento `down`. Questo metodo consiste nell'escludere delle righe nel training per equilibrare le classi.

6. *Model tuning and evaluation* <br>

Si è scelto il parametro `m` attraverso K-fold Cross Validation con K pari a 10. è stato selezionato m=2 poiché ha associato il valore più alto della ROC.

7. *R packages* <br>

`caret`

8. *References* <br>

Il libro [Feature Engineering and Selection](http://www.feat.engineering/index.html). In particolare le sezioni: 5 per la codifica delle variabili categoriali, 8.2 e 8.4 per i missing.


```{r startup, include = FALSE, message = FALSE, warning = FALSE}

knitr::opts_chunk$set(echo = T, eval=F, message=F, warning=F, error=F, comment = NA, cache=F, R.options=list(width=220))

```



**R code to reproduce the last submission**



```{r}
rm(list=ls())
train=read.csv("http://bee-fore.s3-eu-west-1.amazonaws.com/datasets/112.csv",stringsAsFactors = T)
test=read.csv("http://bee-fore.s3-eu-west-1.amazonaws.com/datasets/113.csv",stringsAsFactors = T)
test$Class = NA
n = nrow(train)
m = nrow(test)
combi = rbind(train,test)
train = combi[1:n,]
test = combi[(n+1):(n+m),]
combi$education=ifelse(combi$education %in% c("dropped_out_of_college_university",
                                              "dropped_out_of_high_school",       
                                              "dropped_out_of_law_school",        
                                              "dropped_out_of_masters_program",   
                                              "dropped_out_of_med_school",        
                                              "dropped_out_of_ph_d_program",      
                                              "dropped_out_of_space_camp",        
                                              "dropped_out_of_two_year_college"),"ritirato",
                ifelse(combi$education=="graduated_from_high_school","diplomato",
                ifelse(combi$education %in% c("graduated_from_college_university",
                                                            "graduated_from_two_year_college"),"laureato",
                ifelse(combi$education=="graduated_from_law_school","laureato in legge",
                ifelse(combi$education=="graduated_from_masters_program","master post laurea",
                ifelse(combi$education=="graduated_from_ph_d_program","dottorato di ricerca",
                ifelse(combi$education%in% c("graduated_from_med_school","graduated_from_space_camp"),
                                                                 "laureato in ambito scientifico",
               ifelse(combi$education=="high_school","studente scuole superiori",
               ifelse(combi$education=="masters_program","frequentante master",
               ifelse(combi$education%in% c("med_school","space_camp"),"studente in ambito scientifico",
               ifelse(combi$education=="ph_d_program","frequentante dottorato",
               ifelse(combi$education%in% c("two_year_college","college_university" ),"studente",
               ifelse(combi$education%in% c("working_on_college_university","working_on_high_school",
                                            "working_on_masters_program", "working_on_ph_d_program", 
                                            "working_on_two_year_college"),"lavoratore in ambito scolastico",
               ifelse(combi$education=="working_on_law_school","lavoratore scuola di legge",
               ifelse(combi$education%in% c("working_on_med_school" ,"working_on_space_camp" ),"lavoratore scuola di medicina",
               ifelse(combi$education=="law_school","studente scuola di legge","ed_missing"))))))))))))))))
combi$education=as.factor(combi$education)
combi$income=ifelse(combi$income=="inc100000",100000,
             ifelse(combi$income=="inc1000000",1000000,
             ifelse(combi$income=="inc150000",150000,
             ifelse(combi$income=="inc20000",20000,
             ifelse(combi$income=="inc250000",250000,
             ifelse(combi$income=="inc30000",30000,
             ifelse(combi$income=="inc40000",40000,
             ifelse(combi$income=="inc50000",50000,
             ifelse(combi$income=="inc500000",500000,
             ifelse(combi$income=="inc60000",60000,
             ifelse(combi$income=="inc70000",70000,
             ifelse(combi$income=="inc80000",80000,0))))))))))))
combi$income=ifelse(combi$income %in% c(20000,30000,40000,50000),"basso",
             ifelse(combi$income==0,"mancante","alto"))
combi$income=as.factor(combi$income)
combi$last_online=ifelse(combi$last_online<=4,"frequenti","meno_frequenti")
combi$last_online=as.factor(combi$last_online)
combi$smokes=ifelse(combi$smokes %in% c("sometimes","trying_to_quit","when_drinking","yes"),"fumo",
             ifelse(combi$smokes=="no","non fumo","missing"))
combi$smokes=as.factor(combi$smokes)
combi$status=ifelse(combi$status %in% c("available","single"),"single",
             ifelse(combi$status %in% c("maried","seeing_someone"),"occupato","missing"))
combi$status=as.factor(combi$status)
combi$con_cpp=ifelse(combi$cpp_poorly==1,"poca",
              ifelse(combi$cpp_okay==1,"buona",
              ifelse(combi$cpp_fluently,"fluente","nessuna")))
combi$con_cpp=as.factor(combi$con_cpp)
combi=combi[,-c(21,22,23,24)]
combi$con_lisp=ifelse(combi$lisp_poorly==1,"poca",
               ifelse(combi$lisp_okay==1,"buona",
               ifelse(combi$lisp_fluently,"fluente","nessuna")))
combi$con_lisp=as.factor(combi$con_lisp)
combi=combi[,-c(21,22,23,24)]
combi$cpp_and_lisp=ifelse(combi$con_cpp %in% c("poca","buona","fluente") & combi$con_lisp %in% c("poca","buona","fluente"), "entrambi",
                   ifelse(combi$con_cpp %in% c("poca","buona","fluente") | combi$con_lisp %in% c("poca","buona","fluente"), "almeno uno", "nessuno"))
combi$cpp_and_lisp=as.factor(combi$cpp_and_lisp)
##Creiamo una variabile etnie aggregando le dummies
combi$etnie=ifelse(combi$asian==1,"asian",
            ifelse(combi$middle_eastern==1,"middle-eastern",
            ifelse(combi$indian==1,"indian",
            ifelse(combi$pacific_islander==1,"pacific_islander",
            ifelse(combi$black==1, "black",
            ifelse(combi$hispanic_latin==1,"ispanic_latin",
            ifelse(combi$white==1, "white",
            ifelse(combi$native_american==1, "native_american","other"))))))))
combi=combi[, -c(21:29)]
combi$etnie=as.factor(combi$etnie)
combi$height=ifelse(combi$height==26,68,
             ifelse(combi$height==4,67,
             ifelse(combi$height==3,69,combi$height)))
combi$height[which(combi$height==95 & combi$age==109)]=70
combi$age[which(combi$age==109 & combi$height==70)]=25
train = combi[1:n,]
test = combi[(n+1):(n+m),]
n = nrow(train)
m = nrow(test)
library(caret)
ctrl=trainControl(method = "cv",
                  number = 10,
                  classProbs = TRUE,
                  summaryFunction = twoClassSummary)
ctrl$sampling <- "down"
set.seed(123)
fit.down<- train(Class ~ ., data = train, 
                      method = "rf",
                      metric = "ROC",
                      trControl = ctrl)
phat.down = predict(fit.down, newdata=test,  type = "prob")[,"stem",drop=F]
head(phat.down)
```

